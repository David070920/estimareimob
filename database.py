import os
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker

# Retrieve database connection settings from environment variables with defaults matching docker-compose
POSTGRES_USER = os.getenv("POSTGRES_USER", "estimare_user")
POSTGRES_PASSWORD = os.getenv("POSTGRES_PASSWORD", "estimare_pass")
POSTGRES_DB = os.getenv("POSTGRES_DB", "estimare_db")
POSTGRES_HOST = os.getenv("POSTGRES_HOST", "localhost")
POSTGRES_PORT = os.getenv("POSTGRES_PORT", "5432")

# We use postgresql+asyncpg for asynchronous database interactions
DATABASE_URL = f"postgresql+asyncpg://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}"

# Create the async engine
# echo=True is helpful during development to see all SQL queries generated by SQLAlchemy
engine = create_async_engine(DATABASE_URL, echo=True, future=True)

# Create a customized AsyncSession class using async_sessionmaker
AsyncSessionLocal = async_sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False,
    autoflush=False
)

async def get_db_session():
    """
    Dependency to provide a database session for database operations.
    Yields an AsyncSession and ensures it's correctly closed/rolled back after use.
    """
    async with AsyncSessionLocal() as session:
        try:
            yield session
        except Exception as e:
            await session.rollback()
            raise e
        finally:
            await session.close()

async def init_db(base_metadata):
    """
    Initialize the database, creating all tables defined by SQLAlchemy metadata.
    NOTE: In a production setting, you should use a migration tool like Alembic.
    """
    async with engine.begin() as conn:
        # Create all tables in the database asynchronously
        await conn.run_sync(base_metadata.create_all)
